{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 8331127,
     "sourceType": "datasetVersion",
     "datasetId": 4946951
    }
   ],
   "dockerImageVersionId": 30684,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "# # install google chrome\n# !wget https://dl.google.com/linux/linux_signing_key.pub\n# !sudo apt-key add linux_signing_key.pub\n# !echo 'deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main' >> /etc/apt/sources.list.d/google-chrome.list\n# !sudo apt-get -y update\n# !sudo apt-get install -y google-chrome-stable\n\n# # install chromedriver\n# # !apt-get install -y qq unzip\n# !wget -O /tmp/chromedriver.zip http://chromedriver.storage.googleapis.com/`curl -sS chromedriver.storage.googleapis.com/LATEST_RELEASE`/chromedriver_linux64.zip\n# !unzip /tmp/chromedriver.zip chromedriver -d /usr/bin/",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# # To check Google Chrome's version\n# !google-chrome --version\n\n# # To check Chrome Driver's version\n# !chromedriver -v",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# # Install Firefox\n# !sudo install -d -m 0755 /etc/apt/keyrings\n# !wget -q https://packages.mozilla.org/apt/repo-signing-key.gpg -O- | sudo tee /etc/apt/keyrings/packages.mozilla.org.asc > /dev/null\n# !gpg -n -q --import --import-options import-show /etc/apt/keyrings/packages.mozilla.org.asc | awk '/pub/{getline; gsub(/^ +| +$/,\"\"); if($0 == \"35BAA0B33E9EB396F59CA838C0BA5CE6DC6315A3\") print \"\\nThe key fingerprint matches (\"$0\").\\n\"; else print \"\\nVerification failed: the fingerprint (\"$0\") does not match the expected one.\\n\"}'\n# !echo \"deb [signed-by=/etc/apt/keyrings/packages.mozilla.org.asc] https://packages.mozilla.org/apt mozilla main\" | sudo tee -a /etc/apt/sources.list.d/mozilla.list > /dev/null\n# !echo 'Package: * Pin: origin packages.mozilla.org Pin-Priority: 1000' | sudo tee /etc/apt/preferences.d/mozilla\n# !sudo apt-get update && sudo apt-get install firefox -y",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Install Microsoft Edge\n!curl https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor > microsoft.gpg\n!sudo install -o root -g root -m 644 microsoft.gpg /etc/apt/trusted.gpg.d/\n!sudo sh -c 'echo \"deb [arch=amd64] https://packages.microsoft.com/repos/edge stable main\" > /etc/apt/sources.list.d/microsoft-edge-dev.list'\n!sudo rm microsoft.gpg\n!sudo apt update && sudo apt install microsoft-edge-stable -y",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "!sudo apt install -y python3-selenium",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "!pip install biopython\n!pip install selenium\n!pip install webdriver-manager",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# !pip install tqdm\n# !pip install urllib3",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# from selenium import webdriver\n# from selenium.webdriver.edge.options import Options\n# from selenium.webdriver.edge.service import Service\n# from selenium.webdriver.common.by import By\n# from selenium.webdriver.support import expected_conditions as EC\n# # from selenium.webdriver.support.wait import WebDriverWait\n# from selenium.webdriver.support.ui import WebDriverWait\n# # from webdriver_manager.microsoft import GeckoDriverManager\n# from webdriver_manager.microsoft import EdgeChromiumDriverManager\n\n# from tqdm import tqdm\n# import logging\n# import urllib.request as req\n# import os\n# import numpy as np\n\n# def crawl():\n#     # Read fasta file:\n#     prots = read_fasta(SP6_PATH)\n\n#     # Open driver\n#     options = Options()\n# #     options.headless = True\n# #     options = webdriver.FirefoxOptions()\n#     options.add_argument('--headless')\n# #     options.add_argument('--disable-gpu')\n#     options.add_argument('--no-sandbox')\n#     options.add_argument('--disable-dev-shm-usage')\n# #     chrome_options.add_argument(\"--window-size=1920,1080\")\n#     driver = webdriver.Edge(service=Service(EdgeChromiumDriverManager().install()), options=options)\n\n#     error_ids = []\n\n#     # for loop to get file\n#     for _, prot_id in tqdm(enumerate(prots)):\n#         try:\n#             # access Uniprot page\n#             driver.get(f'https://www.uniprot.org/uniprotkb/{prot_id}/entry#structure')\n#             alphafold_url = WebDriverWait(driver, 30).until(\n#                 EC.presence_of_element_located((By.XPATH, \"//a[text()='AlphaFold']\"))\n#             ).get_attribute('href')\n\n#             # redirect to AlphaFold page\n#             driver.get(alphafold_url)\n#             download_url = WebDriverWait(driver, 30).until(\n#                 EC.presence_of_element_located((By.XPATH, \"//a[text()='PDB file ']\"))\n#             ).get_attribute('href')\n\n#             if not os.path.exists(SAVE_DIR):\n#                 os.makedirs(SAVE_DIR, exist_ok=True)\n\n#             filename = SAVE_DIR + '/' + download_url.split('/')[-1]\n#             req.urlretrieve(download_url, filename)\n\n#         except Exception as e:\n#             error_ids.append(prot_id)\n#             logging.exception(e)\n\n#     np.savetxt(KAGGLE_DIR + '/error_ids.txt', error_ids, fmt=\"%s\")\n#     driver.close()",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import logging\n\n\nclass Logger(object):\n    def __init__(self, filename=None, use_console: bool = False):\n        # reset logging to default\n        logging.root.handlers = []\n        self.log_dir = WORKING_DIR\n        self.filename = filename\n        self.use_console = use_console\n        self.logger = logging.getLogger(__name__)\n        self._configure_logging()\n\n    def _configure_logging(self):\n        formatter = logging.Formatter(\n            fmt='%(asctime)s (%(name)s:%(lineno)d) [%(levelname)s]: %(message)s',\n            datefmt='%m/%d/%Y %I:%M:%S %p'\n        )\n\n        file_handler = logging.FileHandler(self.filename, encoding='utf-8', delay=False)\n        file_handler.setFormatter(formatter)\n        self.logger.addHandler(file_handler)\n\n        if self.use_console:\n            stream_handler = logging.StreamHandler()\n            stream_handler.setFormatter(formatter)\n            self.logger.addHandler(stream_handler)\n\n        self.logger.setLevel(logging.DEBUG)\n\n    def info(self, msg):\n        return self.logger.info(msg)\n\n    def warning(self, msg):\n        return self.logger.warning(msg)\n\n    def error(self, msg):\n        return self.logger.error(msg)\n",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "import time\n",
    "# import time\n",
    "import urllib.request as req\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.options import Options\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from webdriver_manager.microsoft import EdgeChromiumDriverManager\n",
    "\n",
    "# UNIPROT_URL = 'https://www.uniprot.org/uniprot'\n",
    "WORKING_DIR = '/kaggle/working'\n",
    "INPUT_DIR = '/kaggle/input/crawler-cache'\n",
    "SP6_PATH = f'{INPUT_DIR}/train_set.fasta'\n",
    "SAVE_DIR = f'{WORKING_DIR}/pdb'\n",
    "\n",
    "# options = webdriver.ChromeOptions()\n",
    "# driver = webdriver.Chrome(options=options)\n",
    "\n",
    "logger = Logger(filename=f'{WORKING_DIR}/crawler.log', use_console=True)\n",
    "\n",
    "\n",
    "def extract_prot_ids_fasta(fasta_file=SP6_PATH):\n",
    "    prot_ids = []\n",
    "    records = SeqIO.parse(fasta_file, 'fasta')\n",
    "    for record in records:\n",
    "        annotation = str(record.id).split('|')\n",
    "        prot_ids.append(annotation[0])\n",
    "    return prot_ids\n",
    "\n",
    "\n",
    "def load_cache():\n",
    "    done_ids = np.loadtxt(f'{INPUT_DIR}/done_ids.txt', dtype=str)\n",
    "    missing_ids = np.loadtxt(f'{INPUT_DIR}/missing_ids.txt', dtype=str)\n",
    "    return done_ids.tolist(), missing_ids.tolist()\n",
    "\n",
    "\n",
    "def save_cache(done_ids, missing_ids):\n",
    "    np.savetxt(fname=f'{WORKING_DIR}/done_ids.txt', X=done_ids, fmt='%s')\n",
    "    np.savetxt(fname=f'{WORKING_DIR}/missing_ids.txt', X=missing_ids, fmt='%s')\n",
    "\n",
    "\n",
    "# First try to download\n",
    "def download_pdb_by_alphafold():\n",
    "    prot_ids = extract_prot_ids_fasta()\n",
    "    if not os.path.exists(SAVE_DIR):\n",
    "        os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "    done_ids, missing_ids = load_cache()\n",
    "    for i, prot_id in enumerate(prot_ids):\n",
    "        if i > 0 and i % 100 == 0:\n",
    "            logger.info(f'Processing {i}/{len(prot_ids)} records')\n",
    "        if prot_id not in done_ids and prot_id not in missing_ids:\n",
    "            download_url = f'https://alphafold.ebi.ac.uk/files/AF-{prot_id}-F1-model_v4.pdb'\n",
    "            filename = SAVE_DIR + f'/AF-{prot_id}-F1-model_v4.pdb'\n",
    "            try:\n",
    "                req.urlretrieve(download_url, filename)\n",
    "                logger.info(f'Downloaded at {filename}')\n",
    "                done_ids.append(prot_id)\n",
    "            except Exception as e:\n",
    "                logger.error(f'Failed to download {prot_id}: {e}')\n",
    "                missing_ids.append(prot_id)\n",
    "            if i > 0 and i % 100 == 0:\n",
    "                # logger.info(f'Processing thought {i} records')\n",
    "                save_cache(done_ids, missing_ids)\n",
    "\n",
    "        # time.sleep(3)  # prevent bot detection (do not necessary)\n",
    "\n",
    "    # save after running\n",
    "    save_cache(done_ids, missing_ids)\n",
    "\n",
    "\n",
    "# Retry\n",
    "def retry_download_from_uniprot():\n",
    "    convert_ids = {}\n",
    "    done_ids, missing_ids = load_cache()\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    # options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    # options.add_argument(\"--window-size=1920,1080\")\n",
    "\n",
    "    driver = webdriver.Edge(service=Service(EdgeChromiumDriverManager().install()), options=options)\n",
    "    for i, prot_id in enumerate(missing_ids):\n",
    "        driver.get(f'https://www.uniprot.org/uniprotkb/{prot_id}/entry#structure')\n",
    "        time.sleep(3)\n",
    "        try:\n",
    "            # Retry downloading ids missing from downloading process above by accessing from uniprot page\n",
    "            current_url = driver.current_url\n",
    "            af_url = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//a[text()='AlphaFold\"))\n",
    "            ).get_attribute('href')\n",
    "            new_prot_id = current_url.split('/')[-2]  # retrieve new prot_id\n",
    "            driver.get(af_url)\n",
    "            time.sleep(3)\n",
    "            download_url = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//a[text()='PDB file ']\"))\n",
    "            ).get_attribute('href')\n",
    "            filename = f'{SAVE_DIR}/AF-{new_prot_id}-F1-model_v4.pdb'\n",
    "            try:\n",
    "                req.urlretrieve(download_url, filename)\n",
    "                missing_ids = missing_ids.remove(prot_id)\n",
    "                done_ids = done_ids.append(prot_id)\n",
    "                if prot_id not in convert_ids.keys():\n",
    "                    convert_ids[prot_id] = new_prot_id\n",
    "                time.sleep(3)\n",
    "            except Exception as e:\n",
    "                logger.error(f'Failed to download {prot_id}: {e}')\n",
    "        except Exception:\n",
    "            logger.error(f'No AlphaFoldl url found')\n",
    "\n",
    "        if i > 0 and i % 100 == 0:  # save cache after every 100 epochs\n",
    "            save_cache(done_ids, missing_ids)\n",
    "\n",
    "    # Save convert ids of success retrying and update cache\n",
    "    save_cache(done_ids, missing_ids)\n",
    "    with open(f'{WORKING_DIR}/convert_ids.json', 'w') as f:\n",
    "        json.dump(convert_ids, f)\n",
    "\n",
    "    # close driver\n",
    "    driver.close()\n",
    "\n",
    "\n",
    "def crawl():\n",
    "    download_pdb_by_alphafold()\n",
    "    retry_download_from_uniprot()"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "crawl()",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# !pip list",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
